{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>My name is Sophia. I'm a first-year direct-entry physics PhD student studying 21-cm hydrogen intensity mapping.</p>"},{"location":"#overview","title":"Overview","text":"<p>As a cosmologist in training, curiosity about the implications of the physics governing the largest scales and earliest times of the universe drives my everyday work and long-term aspirations to work as a permanent researcher at an independent research institute. </p> <p>Working at the intersection of the McGill Radio Lab and McGill Cosmic Dawn Group, I explore mainly 21 cm hydrogen (see the equation and discussion below, as well as this review paper) intensity mapping, with an eye towards the burgeoning Canadian Hydrogen Observatory and Radio-Transient Detector (CHORD).</p>"},{"location":"#principal-astrophysical-signal-of-interest","title":"Principal astrophysical signal of interest","text":"<p>This relative occupance equation lies at the heart of the ground-state hydrogen spin flip transition with a 21 cm wavelength. This transition is classically forbidden, but the overwhelming abundance of hydrogen in the universe (of the ~5\\% of the universe comprising baryonic (\"everyday\") matter, ~75\\% of this is hydrogen) means that the signal is relatively strong.</p> <p>$$\\frac{n_1}{n_0}=3\\exp{\\frac{h}{k_B}\\frac{\\nu_{21}}{T_s}}$$ </p>"},{"location":"#website-philosophy","title":"Website philosophy","text":"<p>As a graduate student, I am at the crossroads of my career. I am no longer the undergraduate at a liberal arts college that I once was. Since then, I have grown as a researcher and developed more clarity in my research goals. I am also not yet the fully-fledged experienced researcher I strive to be. Graduate school is my test bed for developing new programming, hardware, collaboration, communication, and teaching skills. At this crossroads, I am exploring avenues such as this website for forging new professional presence and connectivity. </p> <p>In other sections of this site, I dive further into my research, recent projects and background.</p>"},{"location":"#chord-instrument-schematic-map","title":"CHORD instrument schematic map","text":"<p>Image source: CHORD Wiki.</p> <p>CHORD is a drift-scan telescope, meaning it cannot be mechanically configured to point at different areas of the sky. Instead, it views different parts of the sky as the earth rotates. It is an interferometer, meaning the data processing pipeline includes signal processing concepts such as aperture synthesis and beam forming (to learn more about radio interferometer data processing, I recommend this e-textbook) to mimic the effect of a larger telescope dish without directly confronting the associated technical challenges. In contrast to often-discussed very-long baseline interferometry (VLBI) telescopes such as the Event Horizon Telescope (EHT) which are used for\u2014among other things\u2014imaging, CHORD is designed with power spectrum creation in mind, and benefits from the higher signal-to-noise ratio (SNR) resulting from a relatively dense network of short baselines. Still, its uv-coverage is supplemented by observing jointly at the CHORD core and outlying outrigger stations. </p>"},{"location":"about/","title":"About","text":""},{"location":"about/#introduction","title":"Introduction","text":"<p>I'm a first-year direct-entry doctoral student at McGill University. My longtime interests in understanding the fundamental workings of the universe have led me to radio cosmology. I graduated magna cum laude from Dartmouth College in 2024 with an A.B. in Physics (thesis with high honors) and minor in astronomy. Currently, I work with Adrian Liu and Cynthia Chiang at the intersection of cosmology theory-computation and instrumentation-observation. I'm working towards characterizing systematics in 21 cm hydrogen intensity mapping data from the Canadian Hydrogen Observatory and Radio-transient Detector (CHORD) by preparing cosmological forecasts and examining galaxy cross-correlations. </p> <p>My journey towards studying cosmology at the Trottier Space Institute (TSI) at McGill University was informed by distilling and re-articulating my research interests during my undergraduate studies. In 2020, my plan upon entering undergraduate studies was to pursue both chemistry and astronomy. Although conducting computational chemistry research on semiconducting polymers proved an enriching intellectual experience, I realized I was more inspired to learn about the larger scales of space than the microscales of molecules and atoms. </p> <p>After conducting heliospheric physics research during 2022 and 2023, I realized I was more interested in larger spatial scales and big-picture understandings of the universe. Subsequently, I became enthralled with radio astronomy while participating in a Research Experience for Undergraduates (REU) at MIT Haystack Observatory. My project consisted of characterizing the gravitationally lensed blazar using very-long baseline interferometry (VLBI) imaging, single-dish molecular line identification, and periodicity analysis of multiwavelength light curves. I continued developing this work into an undergraduate thesis, and applied to graduate school with the idea of diving further into radio astronomy but connecting more directly with the cosmological big picture of her undergraduate work.</p> <p>I have presented my work at several home institution poster sessions, the 243rd meeting of the American Astronomical Society, and the end-of-program symposium at MIT Haystack Observatory. I also enjoy working with students, such as in my capacities as a teaching assistant both at Dartmouth College and McGill University and working as a peer tutor at Dartmouth College and Exeter High School in Exeter, New Hampshire. I also enjoy conducting physics outreach as a volunteer at TSI. For more information, please consult my LinkedIn profile.</p>"},{"location":"about/#outreach","title":"Outreach","text":"<p>AFTER WE COMPLETE THE OUTREACH SESSION, I WILL PASTE THE PRODUCT OF THIS ACTIVITY HERE.</p>"},{"location":"about/#other-interests","title":"Other Interests","text":"<ul> <li>Hiking</li> <li>Crocheting</li> <li>Cooking</li> </ul>"},{"location":"about/#cv","title":"CV","text":""},{"location":"about/cooking/","title":"Cooking","text":""},{"location":"about/cooking/#improvisation-and-synthesis","title":"Improvisation and synthesis","text":"<p>Some recent highlights have been</p> <ul> <li>Argentine x Georgian: empanadas de fugazzeta in a mkhlovani form factor</li> <li>Korean x Italian: homemade gnocchi with banchan</li> <li>Persian x diner: chocolate\u2013tahini\u2013preserved lime muffins</li> <li>Indian x Levantine: paratha dough and technique, but layered with za'atar and olive oil instead of ghee and cumin</li> </ul>"},{"location":"about/crocheting/","title":"Crocheting","text":""},{"location":"about/crocheting/#crocheting","title":"Crocheting","text":"<p>Some recent projects include:</p> <ul> <li>Striped Tunisian crochet sweater vest</li> <li>single crochet hyper-circle with a 65:1 circumference-radius ratio</li> <li>freehand miniature octopus</li> </ul>"},{"location":"about/hiking/","title":"Hiking","text":"<p>Selected favorite hikes:</p>"},{"location":"about/hiking/#franconia-ridge-new-hampshire-us","title":"Franconia Ridge (New Hampshire, US)","text":"<p>During the summer of 2023, my REU cohort spent a lot of time together, even outside our research interactions. We went on eight hikes together during our ten-week program, increasing nearly monotonically in ambitiousness. Our final hike, in the middle of August, led us to Franconia Ridge. One of my friends took the picture where I'm standing on the third of four peaks we crossed while traversing the ridge.</p> <p> </p>"},{"location":"about/hiking/#prc04-fai-caldeira-faial-acores-pt","title":"PRC04 FAI - Caldeira (Faial, A\u00e7ores, PT)","text":"<p>Unfortunately, I don't have pictures ... this was when I was 13 years old and didn't have a smartphone. Instead, here's the AllTrails listing.</p>"},{"location":"about/hiking/#cami-da-ronda-sa-tuna-sa-riera-catalunya-es","title":"Cam\u00ed da Ronda (Sa Tuna / Sa Riera, Catalunya, ES)","text":"<p>Technically, this is a path paved with stones, but it still felt a bit adventurous because the path was built into a cliffside. I was fortunate enough to visit on a gorgeous day towards the end of September 2022, when the Mediterranean was glowing.</p>"},{"location":"about/hiking/#mount-monroe-via-the-ammonoosuc-ravine-trail-and-lakes-of-the-clouds-hut-new-hampshire-us","title":"Mount Monroe via the Ammonoosuc Ravine Trail and Lakes of the Clouds Hut (New Hampshire, US)","text":"<p>I actually did two very similar hikes stemming from the Ammonoosuc Ravine Trail about three weeks apart, during the summer of 2023. Towards the end of July, I hiked to the Hut with a couple REU friends. It was so amazing that I returned to the area in early August with my brother. This time, we turned south at the hut and trekked up a little spur to Mount Monroe.  </p> <p>My friend Nancy took a picture of me and my friend Marissa on the trail leading northeast of the Appalachian Mountain Club hut</p> <p> Looking down at the Hut from the flank of Mount Monroe</p>"},{"location":"about/hiking/#mount-moosilauke-new-hampshire-us","title":"Mount Moosilauke, (New Hampshire, US)","text":"<p>I did my undergrad studies at Dartmouth, which runs a lodge at the base of Mount Moosilauke. Until I hiked the mountain at the end of July 2023 with some REU friends, strangely enough I'd only been to the lodge once before, for a school trip. </p> <p></p>"},{"location":"projects/","title":"Projects","text":""},{"location":"projects/#projects","title":"Projects","text":"<p>At the moment, two projects I'm working on are an inverse power spectrum calculator and a computational physics problem set.</p> <ul> <li>My inverse power spectrum calculator will come in handy as I continue to work with short-baseline 21 cm interferometric data.</li> <li>My current computational physics problem set is on Fourier transforms, but I'm still working on it. On my last assignment for PHYS 512, I ran some MCMC simulations to estimate uncertainty in Lambda-CDM cosmological parameters. To reflect a prior on the tau parameter, I compared the effects of importance sampling to those of running a constrained chain. I discuss this in more detail here.</li> </ul>"},{"location":"projects/data_project/","title":"Index","text":""},{"location":"projects/data_project/#data-project","title":"Data Project","text":"<p>Here are the results of my Bayesian MCMC for Planck data using a chi-squared function calculated using the CAMB software. </p> importance sampling constrained chain H_0 67.78 \u00b1 0.77 67.70 \u00b1 0.69 \u03a9_b h^2 0.02230 \u00b1 0.00017 0.02229 \u00b1 0.00015 \u03a9_c h^2 0.1187 \u00b1 0.0017 0.1188 \u00b1 0.0016 \u03c4 0.05734 \u00b1 0.00723 0.0540 \u00b1 0.000 A_S 2.104e-09 \u00b1 0.031e-09 2.091e-09 \u00b1 0.008e-09 n_s 0.9707 \u00b1 0.0040 0.9702 \u00b1 0.0039 <p>The full data I used to run these simulations is available here.</p>"},{"location":"projects/python_project/ips/","title":"Ips","text":"In\u00a0[1]: Copied! <pre>import numpy as np\nfrom matplotlib import pyplot as plt\n</pre> import numpy as np from matplotlib import pyplot as plt In\u00a0[2]: Copied! <pre>def ips(P,k,Lsurvey):\n    '''\n    P = power spectrum\n    k = wavenumber-space points at which the power spectrum is sampled\n    Lsurvey = length of a simulation cube side, in Mpc\n    '''\n    # helper variable setup\n    k=k.real # nonzero imag part would be a mistake\n    P=P.real # nonzero imag part would be a mistake\n    Npix=len(P)\n    assert(Npix%2==0)\n    Delta = Lsurvey/Npix # voxel side length\n    dr3 = Delta**3 # voxel volume\n    twopi = 2*np.pi\n    V=Lsurvey**3\n    Nsamp=Npix**3\n    r=twopi/(Lsurvey*k)\n    \n    # center-origin r grid    \n    rgrid=np.zeros((Npix,Npix,Npix))\n    rmags=np.arange(0,Lsurvey//2,Delta) # r magnitudes\n    rmags=np.arange(-Lsurvey//2,Lsurvey//2,Delta) # r magnitudes\n    for ii in range(Npix):\n        for jj in range(Npix):\n            for kk in range(Npix):\n                rgrid[ii,jj,kk]=np.sqrt(rmags[ii]**2+rmags[jj]**2+rmags[kk]**2)\n    \n    # take appropriate draws from normal distributions to populate the real part of T-tilde\n    sigmas=np.flip(np.sqrt(V*P/2)) # has Npix elements ... each element describes the T-tilde values in that k-bin ... flip to anticipate the fact that I'm working in r-space but calculated this vector in k-space\n    Ttre=np.zeros((Npix,Npix,Npix)) # this &amp; next - to hold the grid of T-tilde values\n    binidxs=np.digitize(rgrid,r,right=False) # must pass x,bins; rgrid is the big box and r has floors\n    for i,binedge in enumerate(r):\n        sig=sigmas[i]\n        here=np.nonzero(i==binidxs) # all box indices where the corresp bin index is the ith binedge (iterable)\n        numhere=len(np.argwhere(i==binidxs)) # number of voxels in the bin we're currently considering\n        samps=np.random.normal(scale=sig, size=(numhere,)) # samples for filling the current bin\n        if (numhere&gt;0):\n            bef=len(np.argwhere(Ttre))\n            Ttre[here]=samps \n    \n    # use symmetry to popuate the imaginary part of T-tilde\n    Ttim=np.zeros((Npix,Npix,Npix))\n    Ttim[:,:,:Npix//2]=np.flip(Ttre[:,:,Npix//2:],axis=2)\n    Ttim[:,:,Npix//2:]=np.flip(Ttre[:,:,:Npix//2],axis=2)\n    \n    # stitch together T-tilde from its populated components, and iffshift-&gt;ifftn-&gt;fftshift\n    Tt=np.array(Ttre+1j*Ttim,dtype='complex')\n    np.savetxt('check_Tt.txt',np.reshape(Tt,(Npix**3,)))\n    Tts=np.fft.ifftshift(Tt) # bring the origin to the corner\n    Ts=np.fft.ifftn(Tts) # inverse FT\n    T=(np.fft.fftshift(Ts)/dr3).real # return the origin to the center and take T out of integral-land\n    \n    return rgrid,T\n</pre> def ips(P,k,Lsurvey):     '''     P = power spectrum     k = wavenumber-space points at which the power spectrum is sampled     Lsurvey = length of a simulation cube side, in Mpc     '''     # helper variable setup     k=k.real # nonzero imag part would be a mistake     P=P.real # nonzero imag part would be a mistake     Npix=len(P)     assert(Npix%2==0)     Delta = Lsurvey/Npix # voxel side length     dr3 = Delta**3 # voxel volume     twopi = 2*np.pi     V=Lsurvey**3     Nsamp=Npix**3     r=twopi/(Lsurvey*k)          # center-origin r grid         rgrid=np.zeros((Npix,Npix,Npix))     rmags=np.arange(0,Lsurvey//2,Delta) # r magnitudes     rmags=np.arange(-Lsurvey//2,Lsurvey//2,Delta) # r magnitudes     for ii in range(Npix):         for jj in range(Npix):             for kk in range(Npix):                 rgrid[ii,jj,kk]=np.sqrt(rmags[ii]**2+rmags[jj]**2+rmags[kk]**2)          # take appropriate draws from normal distributions to populate the real part of T-tilde     sigmas=np.flip(np.sqrt(V*P/2)) # has Npix elements ... each element describes the T-tilde values in that k-bin ... flip to anticipate the fact that I'm working in r-space but calculated this vector in k-space     Ttre=np.zeros((Npix,Npix,Npix)) # this &amp; next - to hold the grid of T-tilde values     binidxs=np.digitize(rgrid,r,right=False) # must pass x,bins; rgrid is the big box and r has floors     for i,binedge in enumerate(r):         sig=sigmas[i]         here=np.nonzero(i==binidxs) # all box indices where the corresp bin index is the ith binedge (iterable)         numhere=len(np.argwhere(i==binidxs)) # number of voxels in the bin we're currently considering         samps=np.random.normal(scale=sig, size=(numhere,)) # samples for filling the current bin         if (numhere&gt;0):             bef=len(np.argwhere(Ttre))             Ttre[here]=samps           # use symmetry to popuate the imaginary part of T-tilde     Ttim=np.zeros((Npix,Npix,Npix))     Ttim[:,:,:Npix//2]=np.flip(Ttre[:,:,Npix//2:],axis=2)     Ttim[:,:,Npix//2:]=np.flip(Ttre[:,:,:Npix//2],axis=2)          # stitch together T-tilde from its populated components, and iffshift-&gt;ifftn-&gt;fftshift     Tt=np.array(Ttre+1j*Ttim,dtype='complex')     np.savetxt('check_Tt.txt',np.reshape(Tt,(Npix**3,)))     Tts=np.fft.ifftshift(Tt) # bring the origin to the corner     Ts=np.fft.ifftn(Tts) # inverse FT     T=(np.fft.fftshift(Ts)/dr3).real # return the origin to the center and take T out of integral-land          return rgrid,T      In\u00a0[3]: Copied! <pre>Lsurvey=100 # Mpc\nkfl,P=np.genfromtxt('ps_wn_20px.txt',dtype='complex').T\n</pre> Lsurvey=100 # Mpc kfl,P=np.genfromtxt('ps_wn_20px.txt',dtype='complex').T In\u00a0[4]: Copied! <pre>rgen,Tgen=ips(P,kfl,Lsurvey)\n</pre> rgen,Tgen=ips(P,kfl,Lsurvey) In\u00a0[5]: Copied! <pre>Npix=20 # hard-code b/c I know which generated power spectrum I'm dealing with\nfig,axs=plt.subplots(4,5,figsize=(15,9))\nfor k in range(Npix):\n    i=k%4\n    j=k//4\n    im=axs[i,j].imshow(Tgen[:,:,k])\n    fig.colorbar(im)\n    axs[i,j].set_title('slice='+str(k+1)+'/20')\nplt.suptitle('slices of Tmeas generated by my IPS function - handling the PS I calculated of a white noise box')\nplt.tight_layout()\nplt.show()\n</pre> Npix=20 # hard-code b/c I know which generated power spectrum I'm dealing with fig,axs=plt.subplots(4,5,figsize=(15,9)) for k in range(Npix):     i=k%4     j=k//4     im=axs[i,j].imshow(Tgen[:,:,k])     fig.colorbar(im)     axs[i,j].set_title('slice='+str(k+1)+'/20') plt.suptitle('slices of Tmeas generated by my IPS function - handling the PS I calculated of a white noise box') plt.tight_layout() plt.show() <p>what about averaging over all the slices?</p> In\u00a0[6]: Copied! <pre>Tavg=np.mean(Tgen,axis=2)\nplt.imshow(Tavg)\nplt.colorbar()\nplt.title('AVERAGED OVER ALL SLICES Tmeas generated by my IPS function - handling the PS I calculated of a white noise box')\nplt.tight_layout()\nplt.show()\n</pre> Tavg=np.mean(Tgen,axis=2) plt.imshow(Tavg) plt.colorbar() plt.title('AVERAGED OVER ALL SLICES Tmeas generated by my IPS function - handling the PS I calculated of a white noise box') plt.tight_layout() plt.show() <p>average over several realizations</p> In\u00a0[7]: Copied! <pre>nrealiz=20\nallT=[]\nfor i in range(nrealiz):\n    rgen,Tgen=ips(P,kfl,Lsurvey)\n    allT.append(Tgen)  \nallT=np.array(allT)\nprint('allT.shape is',allT.shape)\nmeanT=np.mean(allT,axis=3) # average the brain-melting list of 3D arrays back down into a single 3d array\n</pre> nrealiz=20 allT=[] for i in range(nrealiz):     rgen,Tgen=ips(P,kfl,Lsurvey)     allT.append(Tgen)   allT=np.array(allT) print('allT.shape is',allT.shape) meanT=np.mean(allT,axis=3) # average the brain-melting list of 3D arrays back down into a single 3d array <pre>allT.shape is (20, 20, 20, 20)\n</pre> In\u00a0[8]: Copied! <pre>fig,axs=plt.subplots(4,5,figsize=(15,9))\nfor k in range(Npix):\n    i=k%4\n    j=k//4\n    im=axs[i,j].imshow(meanT[:,:,k])\n    fig.colorbar(im)\n    axs[i,j].set_title('slice='+str(k+1)+'/20')\nplt.suptitle('AVERAGE OVER '+str(nrealiz)+' REALIZATIONS: slices of Tmeas generated by my IPS function - handling the PS I calculated of a white noise box')\nplt.tight_layout()\nplt.show()\n</pre> fig,axs=plt.subplots(4,5,figsize=(15,9)) for k in range(Npix):     i=k%4     j=k//4     im=axs[i,j].imshow(meanT[:,:,k])     fig.colorbar(im)     axs[i,j].set_title('slice='+str(k+1)+'/20') plt.suptitle('AVERAGE OVER '+str(nrealiz)+' REALIZATIONS: slices of Tmeas generated by my IPS function - handling the PS I calculated of a white noise box') plt.tight_layout() plt.show() <p>...and then average over all the slices on top of that?!</p> In\u00a0[9]: Copied! <pre>meanTslice=np.mean(meanT,axis=2)\nplt.imshow(meanTslice)\nplt.colorbar()\nplt.title('AVERAGED OVER REALIZATIONS AND THEN SLICES Tmeas generated by my IPS function - handling the PS I calculated of a white noise box')\nplt.tight_layout()\nplt.show()\n</pre> meanTslice=np.mean(meanT,axis=2) plt.imshow(meanTslice) plt.colorbar() plt.title('AVERAGED OVER REALIZATIONS AND THEN SLICES Tmeas generated by my IPS function - handling the PS I calculated of a white noise box') plt.tight_layout() plt.show() In\u00a0[10]: Copied! <pre>nrealiz=20\nallTflat=[]\nfor i in range(nrealiz):\n    rgen,Tgen=ips(P,kfl,Lsurvey)\n    flatTgen=np.mean(Tgen,axis=2)\n    allTflat.append(flatTgen)  \nallTflat=np.array(allTflat)\n# print('allTflat.shape is',allTflat.shape)\nmeanT=np.mean(allTflat,axis=2) # average the list of 3D arrays back down into a 2D array\n# print('meanT.shape is',meanT.shape)\n</pre> nrealiz=20 allTflat=[] for i in range(nrealiz):     rgen,Tgen=ips(P,kfl,Lsurvey)     flatTgen=np.mean(Tgen,axis=2)     allTflat.append(flatTgen)   allTflat=np.array(allTflat) # print('allTflat.shape is',allTflat.shape) meanT=np.mean(allTflat,axis=2) # average the list of 3D arrays back down into a 2D array # print('meanT.shape is',meanT.shape) In\u00a0[11]: Copied! <pre>plt.imshow(meanT)\nplt.colorbar()\nplt.title('AVERAGED OVER SLICES AND THEN REALIZATIONS Tmeas generated by my IPS function - handling the PS I calculated of a white noise box')\nplt.tight_layout()\nplt.show()\n</pre> plt.imshow(meanT) plt.colorbar() plt.title('AVERAGED OVER SLICES AND THEN REALIZATIONS Tmeas generated by my IPS function - handling the PS I calculated of a white noise box') plt.tight_layout() plt.show()"},{"location":"projects/python_project/python_project/","title":"Python project","text":"In\u00a0[4]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\n</pre> import numpy as np import matplotlib.pyplot as plt <p>Once imported we can do a lot of things. Here is an example of calculating something:</p> In\u00a0[7]: Copied! <pre>x = np.linspace(-3*np.pi, 3 * np.pi)\ny = np.sin(x)\nprint (x[:5])\nprint (y[:5])\n</pre> x = np.linspace(-3*np.pi, 3 * np.pi) y = np.sin(x) print (x[:5]) print (y[:5])  <pre>[-9.42477796 -9.04009315 -8.65540833 -8.27072352 -7.8860387 ]\n[-3.67394040e-16 -3.75267005e-01 -6.95682551e-01 -9.14412623e-01\n -9.99486216e-01]\n</pre> In\u00a0[8]: Copied! <pre>plt.plot(x,y)\n</pre> plt.plot(x,y) Out[8]: <pre>[&lt;matplotlib.lines.Line2D at 0x7abb039e6e90&gt;]</pre> In\u00a0[10]: Copied! <pre>def get_sqrt_real(x):\n    if x &gt; 0:\n        return np.sqrt(x)\n    else:\n        return np.nan\n</pre> def get_sqrt_real(x):     if x &gt; 0:         return np.sqrt(x)     else:         return np.nan <p>If we try to run this on a numpy array, it wont work</p> In\u00a0[12]: Copied! <pre>x_sqrt = get_sqrt_real(x)\n</pre> x_sqrt = get_sqrt_real(x) <pre>\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\nCell In[12], line 1\n----&gt; 1 x_sqrt = get_sqrt_real(x)\n\nCell In[10], line 2, in get_sqrt_real(x)\n      1 def get_sqrt_real(x):\n----&gt; 2     if x &gt; 0:\n      3         return np.sqrt(x)\n      4     else:\n\nValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()</pre> <p>Instead we can \"vectorize\" the function using <code>np.vectorize</code></p> In\u00a0[13]: Copied! <pre>get_sqrt_real_vec = np.vectorize(get_sqrt_real)\n</pre> get_sqrt_real_vec = np.vectorize(get_sqrt_real) In\u00a0[14]: Copied! <pre>x_sqrt = get_sqrt_real_vec(x)\n</pre> x_sqrt = get_sqrt_real_vec(x) In\u00a0[16]: Copied! <pre>plt.plot(x, x_sqrt)\nplt.xlim(x[0], x[-1])\n</pre> plt.plot(x, x_sqrt) plt.xlim(x[0], x[-1]) Out[16]: <pre>(-9.42477796076938, 9.42477796076938)</pre> In\u00a0[19]: Copied! <pre>np.random.randint(low = 0, high = 100, size=7)\n</pre> np.random.randint(low = 0, high = 100, size=7) Out[19]: <pre>array([78, 65, 49, 47, 65, 39, 93])</pre> In\u00a0[21]: Copied! <pre>np.random.normal(size=7)\n</pre> np.random.normal(size=7) Out[21]: <pre>array([ 0.95110127, -0.52254243,  0.55930288, -0.15204086, -1.07484408,\n       -0.78643181, -0.28677366])</pre> In\u00a0[22]: Copied! <pre>np.random.normal(size=7)\n</pre> np.random.normal(size=7) Out[22]: <pre>array([ 1.04049818,  0.29026636,  0.53497085, -1.14562503,  0.74457319,\n        1.52530604, -0.50886681])</pre> In\u00a0[23]: Copied! <pre>with open(\"../data_project/media/example.csv\", \"w\") as f:\n    f.write(\"#id,value1,value2\\n\")\n    for i in range(1000):\n        idx = np.random.randint(low = 0, high = 1e7)\n        val1 = np.random.normal()\n        val2 = np.random.normal()\n\n        f.write(f\"{idx},{val1},{val2}\\n\")\n</pre> with open(\"../data_project/media/example.csv\", \"w\") as f:     f.write(\"#id,value1,value2\\n\")     for i in range(1000):         idx = np.random.randint(low = 0, high = 1e7)         val1 = np.random.normal()         val2 = np.random.normal()          f.write(f\"{idx},{val1},{val2}\\n\") In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"projects/python_project/python_project/#python-project","title":"Python project\u00b6","text":"<p>In this project we'll show the awesome python package that I'd like to show you. Lets start by importing the package using:</p> <pre>import numpy as np\n</pre>"},{"location":"projects/python_project/python_project/#functions","title":"Functions\u00b6","text":"<p>Let's write a function that will be vectorized by numpy</p>"},{"location":"research/","title":"Research","text":""},{"location":"research/#research","title":"Research","text":"<p>As a researcher, I live at the boundary between theoretical\u2014in the sense of simulations, forecasting, and modeling\u2014and experimental\u2014to the tune of telescope dish troubleshooting\u2014cosmology. I work with one supervisor in each realm and communicate with both groups. At the moment, seeing as it is still merely my second month as a graduate student, I am laying the groundwork for my future thesis project more than working on a fully-fledged project itself. </p> <p>So far, I have written codes to (1) translate a cosmological brightness temperature fluctuation box to a power spectrum, (2) construct such a box as a random realization of the statistics encoded in a power spectrum, and (3) construct Fisher matrices for selected objective functions of interest. Before I undertake my preliminary thesis examination during the Winter 2026 term, I will fully model at least one systematic in CHORD data, including preparing cosmological forecasts using the Fisher matrix formalism and a galaxy cross-correlation analysis. I will extend this line of inquiry as my studies progress and as first light for the CHORD telescope arrives. </p> <p>I don't yet have any papers in peer-reviewed journals, so below I'll link the two most significant reports I've prepared. </p>"},{"location":"research/#selected-publications","title":"Selected Publications","text":"<ul> <li>Undergraduate honors thesis - May 2024</li> <li>REU report - August 2023</li> </ul> <p>A full list of publications can be found here.</p>"},{"location":"research/all_publications/","title":"All publications","text":""},{"location":"research/all_publications/#publications","title":"Publications","text":"<p>I will update this page with real, relevant papers as soon as I contribute as an author to journal articles. For now\u2014i.e. the PHYS 601 assignment where one requirement is to populate a publication page\u2014I will use some assorted articles in various fields which I find fascinating. </p>"},{"location":"research/all_publications/#2024","title":"2024","text":"<ul> <li>\"Constraining cosmology with the CMB \u00d7 line intensity mapping-nulling convergence\" Fronenberg et al., PRD, 2024</li> </ul>"},{"location":"research/all_publications/#2020","title":"2020","text":"<ul> <li>\"Rust,\" How Nornickel is converting the Taymyr Peninsula into pure profit, Kostyuchenko &amp; Kozyrev, \"Novaya Gazeta,\" 2020</li> </ul>"},{"location":"research/all_publications/#2017","title":"2017","text":"<ul> <li>\"What the women have to say,\" women\u2019s perspectives on language, identity and nation in Catalonia, Iveson, University of Roehampton - doctoral thesis, 2017</li> </ul>"},{"location":"research/highlights/reu_report/","title":"Index","text":""},{"location":"research/highlights/reu_report/#reu-report","title":"REU report","text":"<p>I wrote my first not-for-a-class scientific report as a participant in the MIT Haystack Observatory Research Experience for Undergraduates (REU) during the summer of 2023. I used radio-frequency (VLBI, for imaging; and single-dish, for time-monitoring light curves and spectroscopy) and gamma-ray (light curves from the Fermi telescope, for comparison with their radio counterparts) data to construct a case study of the gravitationally lensed blazar PKS 1830-211. For context, a blazar is one \"flavor\" of active galaxy where the characteristic intense multi-frequency emission from the relativistic jet perpendicular to the accretion disk is radio-loud. Within the unified model of active galactic nuclei (AGNs), a blazar is an AGN viewed nearly face-on. </p> <p>My radio interferometric data came from the Korean VLBI Network (KVN), my radio light curves came from the Caltech Owens Valley Radio Observatory (OVRO), and my gamma-ray light curves came from the Fermi space telescope. Due to the condensed ten-week timeframe of the REU program, I did not write observing proposals or otherwise participate in the data acquisition process\u2014rather, my primary advisor provided me with data and relevant context, as necessary. </p> <p>I worked on this REU project between June and August of 2023. By the end of this period, I believed I'd tentatively identified a physically meaningful periodicity in the PKS 1830-211 light curve and a physically meaningful time delay between radio and gamma-ray emission, which I (incorrectly, and based on a misinterpretation of the literature) claimed was consistent with a plasmon (i.e. traveling shock-in-jet) model of blazar jet emission. At this point, I'd also discussed the possibility of performing molecular spectral line analysis for the PKS 1830-211 system with my advisor, but failed to make headway over the course of the summer. I later revisited all of these conclusions and identified several spectral lines during the process of preparing my undergraduate honors thesis.</p> <p>The associated slide presentation and poster I prepared are both linked under the \"Using a Natural Cosmic Telescope to Study a Distant Radio Quasar / Sophia D'Agostino Rubens\" heading (eighth from the top) under 2023 tab of the Haystack REU presentation archive.</p> <p> </p> Schematic representation of the strong gravitational lensing of an active galaxy by an intervening galaxy. In practice, imperfect source-lens-observer alignment means only two of the four theoretical images have appreciable brightness compared to the background. (source: Wikimedia Commons)"},{"location":"research/highlights/undergraduate_honors_thesis/","title":"Index","text":""},{"location":"research/highlights/undergraduate_honors_thesis/#undergraduate-honors-thesis","title":"Undergraduate honors thesis","text":"<p>My undergraduate honors thesis expanded upon the case study of the gravitationally lensed blazar PKS 1830-211 I conducted during my time as a student in the research experience for undergraduates (REU) program at MIT Haystack Observatory. For context, a blazar is one \"flavor\" of active galaxy where the characteristic intense multi-frequency emission from the relativistic jet perpendicular to the accretion disk is radio-loud. Within the unified model of active galactic nuclei (AGNs), a blazar is an AGN viewed nearly face-on. For more context on this project and a contextualization of where my analysis after those ten initial weeks of work fell short, please see the corresponding page.</p> <p>In this thesis, I qualitatively confirm the trends I found in the flux ratios between the NE and SW components of the lensed image of PKS 1830-211, but reinterpret these values according to an updated reading of the literature to conclude that the plasmon (i.e. traveling shock-in-jet) model is still a plausible explanation for the mechanism powering the jet of the quasar in PKS 1830-211, but clarify that this qualifies as a cospatial emission model\u2014meaning emission at different frequencies does not arise from fundamentally different regions of the jet. This conclusion is enhanced by my new result that all possible radio-gamma time delays I might have found during the REU are statistically insignificant.</p> <p>I also re-examine the time-monitoring light curves for the lensed system using more sophisticated validation techniques and find that all periods potentially indicated by a periodogram analysis are statistically insignificant. I used time series folding and folding perturbation to reach this conclusion. Consequently, I cast doubt on the possibility that the jet of the blazar in PKS 1830-211 is precessing with respect to the line of sight, a finding first proposed by Nair et al (2005) and commonly referenced thereafter though not, to my knowledge or after my literature review of order 100 papers on PKS 1830-211, ever independently confirmed.</p> <p>Finally, I identify some molecular transitions in one of the nearly face-on spiral galaxies lensing the source blazar. Although the z=0.19 galaxy does not exhibit any known molecular transitions, the z=0.89 galaxy exhibits over thirty known such transitions. In the data set I had available, I identified five distinct lines: four relatively confidently and echoing literature findings, and one where the only good match available in the Splatalogue was an implausibly large molecule.</p> <p>Shown below is a compilation of my VLBI imaging results. After using the Astronomical Image Processing System (AIPS) to reduce and calibrate my data and the Caltech software implementation of the difference mapping technique (difmap) to prepare the images shown below, I used difmap to perform model fitting and extract the flux values used to construct the ratios I considered in the quantitative part of my VLBI analysis.  </p>"}]}